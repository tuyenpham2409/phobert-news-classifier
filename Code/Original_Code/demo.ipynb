{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","from google.colab import drive\n","import os\n","\n","# Mount Drive (ƒë·ªÉ l·∫•y Model PhoBERT x·ªãn)\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","!pip install streamlit transformers torch vncorenlp -q\n","\n","# T·∫£i c√¥ng c·ª• Cloudflare (Thay th·∫ø Ngrok)\n","!wget -q -O cloudflared-linux-amd64 https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n","!chmod +x cloudflared-linux-amd64\n","\n","# T·∫£i VnCoreNLP (B·∫Øt bu·ªôc ƒë·ªÉ ch·∫°y app)\n","!mkdir -p vncorenlp/models/wordsegmenter\n","!wget -q -P vncorenlp/ https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget -q -P vncorenlp/models/wordsegmenter/ https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget -q -P vncorenlp/models/wordsegmenter/ https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SlXNvXKiEV6","executionInfo":{"status":"ok","timestamp":1764583267426,"user_tz":-420,"elapsed":8460,"user":{"displayName":"Tuy√™n Ph·∫°m","userId":"00807895422532063883"}},"outputId":"68e5bc90-54d7-4be9-bf08-c54709c96cca"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cloudflared-linux-amd64: Text file busy\n"]}]},{"cell_type":"code","source":["app_code = \"\"\"\n","import streamlit as st\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from vncorenlp import VnCoreNLP\n","import re\n","\n","# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N\n","# B·∫°n ki·ªÉm tra k·ªπ ƒë∆∞·ªùng d·∫´n n√†y trong Drive c·ªßa b·∫°n nh√©\n","MODEL_PATH = \"/content/drive/My Drive/NLP Project/Model_PhoBERT\"\n","VNCORENLP_PATH = \"vncorenlp/VnCoreNLP-1.1.1.jar\"\n","\n","id2label = {\n","    0: \"TH·ªÇ THAO ‚öΩ\", 1: \"S·ª®C KH·ªéE üè•\", 2: \"GI√ÅO D·ª§C üéì\",\n","    3: \"PH√ÅP LU·∫¨T ‚öñÔ∏è\", 4: \"KINH DOANH üí∞\", 5: \"TH∆Ø GI√ÉN üòÇ\", 6: \"KHOA H·ªåC C√îNG NGH·ªÜ üñ•Ô∏è\", 7: \"XE C·ªò üèéÔ∏è\",\n","    8: \"ƒê·ªúI S·ªêNG üíÅ‚Äç‚ôÇÔ∏è\", 9: \"TH·∫æ GI·ªöI üåç\"\n","}\n","\n","@st.cache_resource\n","def load_resources():\n","    try:\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n","        rdrsegmenter = VnCoreNLP(VNCORENLP_PATH, annotators=\"wseg\", max_heap_size='-Xmx500m')\n","        return tokenizer, model, rdrsegmenter\n","    except Exception as e:\n","        return None, None, None\n","\n","tokenizer, model, rdrsegmenter = load_resources()\n","\n","def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r'<.*?>', '', text)\n","    text = re.sub(r'http\\S+', '', text)\n","    text = re.sub(r'[^\\w\\s√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë0-9.,?!]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","def preprocess(text):\n","    text = clean_text(text)\n","    try:\n","        sentences = rdrsegmenter.tokenize(text)\n","        return \" \".join([\" \".join(sentence) for sentence in sentences])\n","    except:\n","        return text\n","\n","st.title(\"üì∞ PH√ÇN LO·∫†I TIN T·ª®C (PhoBERT)\")\n","st.write(\"D√°n n·ªôi dung b√†i b√°o v√†o ƒë√¢y:\")\n","input_text = st.text_area(\"\", height=150)\n","\n","if st.button(\"Ph√¢n lo·∫°i\"):\n","    if not tokenizer:\n","        st.error(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y Model t·∫°i: {MODEL_PATH}. H√£y ki·ªÉm tra l·∫°i Drive!\")\n","    elif not input_text.strip():\n","        st.warning(\"Ch∆∞a nh·∫≠p n·ªôi dung!\")\n","    else:\n","        with st.spinner(\"ƒêang ph√¢n t√≠ch...\"):\n","            processed_text = preprocess(input_text)\n","            inputs = tokenizer(processed_text, return_tensors=\"pt\", truncation=True, max_length=256)\n","            with torch.no_grad():\n","                outputs = model(**inputs)\n","            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","            pred_idx = torch.argmax(probs).item()\n","            confidence = probs[0][pred_idx].item()\n","\n","            st.success(f\"K·∫øt qu·∫£: **{id2label[pred_idx]}**\")\n","            st.info(f\"ƒê·ªô tin c·∫≠y: {confidence*100:.2f}%\")\n","            with st.expander(\"Chi ti·∫øt x·ª≠ l√Ω\"):\n","                st.code(processed_text)\n","\"\"\"\n","\n","# Ghi n·ªôi dung v√†o file app.py\n","with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(app_code)\n","\n","print(\" ƒê√£ t·∫°o file app.py th√†nh c√¥ng!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BF9_Navi2Wc","executionInfo":{"status":"ok","timestamp":1764583267459,"user_tz":-420,"elapsed":29,"user":{"displayName":"Tuy√™n Ph·∫°m","userId":"00807895422532063883"}},"outputId":"4c0ae82e-3fb9-4298-ce45-a1081700e3c2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":[" ƒê√£ t·∫°o file app.py th√†nh c√¥ng!\n"]},{"output_type":"stream","name":"stderr","text":["<>:34: SyntaxWarning: invalid escape sequence '\\S'\n","<>:34: SyntaxWarning: invalid escape sequence '\\S'\n","/tmp/ipython-input-67298072.py:34: SyntaxWarning: invalid escape sequence '\\S'\n","  text = re.sub(r'http\\S+', '', text)\n"]}]},{"cell_type":"code","source":["import subprocess\n","import time\n","\n","!streamlit run app.py &>/content/logs.txt &\n","time.sleep(5)\n","\n","print(\" ƒêang t·∫°o ƒë∆∞·ªùng h·∫ßm Cloudflare...\")\n","!nohup ./cloudflared-linux-amd64 tunnel --url http://localhost:8501 > tunnel.log 2>&1 &\n","time.sleep(8)\n","\n","\n","!grep -o 'https://.*\\.trycloudflare.com' tunnel.log | head -n 1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkq9E72Ti7OO","executionInfo":{"status":"ok","timestamp":1764583280828,"user_tz":-420,"elapsed":13368,"user":{"displayName":"Tuy√™n Ph·∫°m","userId":"00807895422532063883"}},"outputId":"af8a0db9-cdcd-4be3-c19a-adad8b770d6a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":[" ƒêang t·∫°o ƒë∆∞·ªùng h·∫ßm Cloudflare...\n","https://televisions-resorts-tex-animated.trycloudflare.com\n"]}]}]}